{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TF_create_network_CIFAR100_PTQ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6cJfsXYZMO1"
      },
      "source": [
        "!pip install tensorflow==2.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIeMkvkCaQNO"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWoEqyMuXFF4"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data(label_mode='coarse')\n",
        "\n",
        "train_images = ((train_images / 255.0) - 0.1307)/0.3081\n",
        "test_images = ((test_images / 255.0) - 0.1307)/0.3081\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9YmGQBQPrdn"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(32, (1, 1), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(32, (1, 1), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(32, (1, 1), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(92, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.DepthwiseConv2D((1, 1), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(92, (1, 1), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(92, (1, 1), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.DepthwiseConv2D((1, 1), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "\n",
        "model.add(layers.Dense(20, activation='softmax'))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ3kc1ItH6kb"
      },
      "source": [
        "opt = tf.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExuMmzfedWYX"
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "it_train = datagen.flow(train_images, train_labels, batch_size=64)\n",
        "steps = int(train_images.shape[0] / 64)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogHFtofXVTC_"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrU-QnNjiyGW"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "\thistory = model.fit(it_train, steps_per_epoch=steps, epochs=50, validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elFa6ufJpvFq"
      },
      "source": [
        "opt = tf.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSLj2Xhvpw-D"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "\thistory = model.fit(it_train, steps_per_epoch=steps, epochs=20, validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "937OdSuqZXa7"
      },
      "source": [
        "model.save(\"network.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNT0GthqHJK_"
      },
      "source": [
        "!wget https://github.com/darkyfoxy/AI_on_STM32/raw/main/network_CIFAR100/network.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK3wG-xYyKvz"
      },
      "source": [
        "model.load_weights(\"/content/network.h5\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfROI9WUYaYF"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikn7cwKNw1-5"
      },
      "source": [
        "TEST_SIZE = 300\n",
        "\n",
        "np.save('input', test_images[:TEST_SIZE]) \n",
        "np.save('output', test_labels[:TEST_SIZE]) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIWfI0rdQXIc"
      },
      "source": [
        "model.save(\"network\")\n",
        "network_dir_path = \"/content/network\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_aPnpFSZZZ3"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "\n",
        "open(\"network_without_optim.tflite\", \"wb\").write(model_no_quant_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkcyMyUNIEnI"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "open(\"network_DRQ.tflite\", \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBLGsgxwKdL2"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([test_images[i].reshape(1, 32, 32, 3).astype(np.float32)])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "open(\"network_FIQ.tflite\", \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYS7suv_OPqc"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([test_images[i].reshape(1, 32, 32, 3).astype(np.float32)])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "open(\"network_INT16_INT8.tflite\", \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvnWM7kIOTSm"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([test_images[i].reshape(1, 32, 32, 3).astype(np.float32)])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8,\n",
        "                                       tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "open(\"network_INT16_INT8_BUILTINS.tflite\", \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB2Br9NfOs5W"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([test_images[i].reshape(1, 32, 32, 3).astype(np.float32)])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "open(\"network_BUILTINS.tflite\", \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rflsS63tPO2p"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([test_images[i].reshape(1, 32, 32, 3).astype(np.float32)])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "open(\"network_FIQ_int_only.tflite\", \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HvKwPuvZbQd"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([test_images[i].reshape(1, 32, 32, 3).astype(np.float32)])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "open(\"network_FIQ_int_only_IIOT.tflite\", \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifw5FzzYLrpV"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(network_dir_path)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "open(\"network_float16.tflite\", \"wb\").write(model_tflite)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}