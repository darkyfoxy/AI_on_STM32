{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_network_MNIST.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXnDTL32PCMi"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HHk6OKhbcnm"
      },
      "source": [
        "train_dataset = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                     transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                                     ])),\n",
        "                        batch_size=200, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False,\n",
        "                   transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                 transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                                 ])),\n",
        "                      batch_size=200, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2YIodKk0Kli"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(28 * 28, 200)\n",
        "      self.fc2 = nn.Linear(200, 200)\n",
        "      self.fc3 = nn.Linear(200, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return F.softmax(x)\n",
        "\n",
        "net = Net()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs_fX3mOQE-G"
      },
      "source": [
        "epochs=15\n",
        "log_interval=10\n",
        "accuracy_hist = []\n",
        "loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "      for batch_idx, (data, target) in enumerate(train_dataset):\n",
        "          v_data, v_target = Variable(data), Variable(F.one_hot(target, num_classes=10).float())\n",
        "          v_data = v_data.view(-1, 28*28)\n",
        "          optimizer.zero_grad()\n",
        "          net_out = net(v_data)\n",
        "          accuracy = (torch.argmax(net_out, 1) == target).sum()/train_dataset.batch_size\n",
        "          loss = criterion(net_out, v_target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          accuracy_hist.append(accuracy)\n",
        "          loss_hist.append(loss.data)\n",
        "          if batch_idx % log_interval == 0:\n",
        "              print('epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tAccuracy: {:.6f} '.format(\n",
        "                  epoch, batch_idx * len(data), len(train_dataset.dataset),\n",
        "                          100. * batch_idx / len(train_dataset), loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Aj1stHevVyy"
      },
      "source": [
        "fig = plt.figure(figsize = (20,10))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(accuracy_hist)\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss_hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9gpcIOxz4X2"
      },
      "source": [
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data, target in test_dataset:\n",
        "    data, target = Variable(data), Variable(target)\n",
        "    data = data.view(-1, 28 * 28)\n",
        "    net_out = net(data)\n",
        "    test_loss += criterion(net_out, Variable(F.one_hot(target, num_classes=10).float())).data\n",
        "    pred = net_out.data.max(1)[1]\n",
        "    correct += pred.eq(target.data).sum()\n",
        "\n",
        "test_loss /= len(test_dataset.dataset)\n",
        "print('Test set: Loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_dataset.dataset),\n",
        "    100. * correct / len(test_dataset.dataset)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-I8j2xgbeyt"
      },
      "source": [
        "net.eval() \n",
        "\n",
        "dummy_input = torch.randn(28 * 28, requires_grad=True)  \n",
        "  \n",
        "torch.onnx.export(net, dummy_input, \"network.onnx\",  \n",
        "      export_params=True, opset_version=10, do_constant_folding=True,\n",
        "      input_names = ['modelInput'], output_names = ['modelOutput']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_xJxJPYU9op"
      },
      "source": [
        "test_size = 1000\n",
        "input = np.zeros([test_size, 28*28])\n",
        "output = np.zeros([test_size, 10])\n",
        "for i in range(test_size):\n",
        "  input[i] = np.array(test_dataset.dataset[i][0][0].view(-1, 28*28))\n",
        "  output[i][test_dataset.dataset[i][1]] = 1.0\n",
        "\n",
        "np.save('input', input)\n",
        "np.save('output', output)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}